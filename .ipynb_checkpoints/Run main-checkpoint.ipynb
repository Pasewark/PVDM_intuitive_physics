{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a687309b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-10 22:09:52.848543: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-10 22:09:53.300460: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "before first stage\n",
      "first stage\n",
      "half half\n",
      "after multi\n",
      "first_stage_main_UCF101_42\n",
      "after create log\n",
      "[2023-04-10 22:09:54.218648] Namespace(exp='first_stage', seed=42, id='main', data='UCF101', batch_size=8, ds=4, pretrain_config='configs/autoencoder/base.yaml', diffusion_config='configs/latent-diffusion/ucf101-ldm-kl-3_res128.yaml', first_stage_folder='', first_model='', scale_lr=False, devicenum='0', n_gpus=1, device=device(type='cuda', index=0), ddconfig={'double_z': False, 'channels': 256, 'resolution': 64, 'timesteps': 15, 'skip': 1, 'in_channels': 4, 'out_ch': 4, 'num_res_blocks': 2, 'attn_resolutions': [], 'splits': 1}, embed_dim=4, lossconfig={'params': {'disc_start': 100000000}}, lr=0.0001, res=64, timesteps=15, skip=1, resume=False, amp=True)\n",
      "[2023-04-10 22:09:54.218688] Log path: ./results/first_stage_main_UCF101_42/\n",
      "after half half\n",
      "[2023-04-10 22:09:54.218699] Loading dataset UCF101 with resolution 64\n",
      "[2023-04-10 22:09:54.218705] Generating model\n",
      "half\n",
      "/home/eric/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/eric/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "loaded pretrained LPIPS loss from ./losses/vgg.pth\n",
      "before first stage train\n",
      "2023-04-10 22:09:56.085867: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-10 22:09:56.085988: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-10 22:09:56.086603: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-10 22:09:56.086724: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-10 22:09:56.086873: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-10 22:09:56.086949: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "first stage train\n",
      "Fail to load scalers. Start from initial point.\n",
      "2023-04-10 22:09:56.148766: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [100]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-04-10 22:09:56.148890: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [100]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-04-10 22:09:56.260864: W tensorflow/tsl/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"NOT_FOUND: Could not locate the credentials file.\". Retrieving token from GCE failed with \"FAILED_PRECONDITION: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata.google.internal\".\n",
      "/home/eric/Documents/Diffusion/intuitive_physics_pvdm/tools/trainer.py:152: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  vid=torch.from_numpy(full_data['image']).permute(0,3,1,2).type(torch.float32)\n",
      "data torch.Size([8, 15, 4, 64, 64]) torch.float32\n",
      "input torch.Size([8, 4, 15, 64, 64])\n",
      "timesformerencoder torch.Size([8, 15, 4, 64, 64])\n",
      "timesformerencoder2 torch.Size([8, 960, 256])\n",
      "first x torch.Size([8, 960, 256])\n",
      "x shape torch.Size([8, 960, 256])\n",
      "x shape torch.Size([8, 960, 256])\n",
      "x shape torch.Size([8, 960, 256])\n",
      "x shape torch.Size([8, 960, 256])\n",
      "x shape torch.Size([8, 960, 256])\n",
      "x shape torch.Size([8, 960, 256])\n",
      "x shape torch.Size([8, 960, 256])\n",
      "x shape torch.Size([8, 960, 256])\n",
      "encode torch.Size([8, 256, 15, 8, 8])\n",
      "decoder torch.Size([8, 256, 15, 8, 8])\n",
      "torch.Size([8, 960, 256])\n",
      "torch.Size([8, 960, 256])\n",
      "torch.Size([8, 960, 256])\n",
      "torch.Size([8, 960, 256])\n",
      "torch.Size([8, 960, 256])\n",
      "torch.Size([8, 960, 256])\n",
      "torch.Size([8, 960, 256])\n",
      "torch.Size([8, 960, 256])\n",
      "torch.Size([8, 960, 256])\n",
      "decode torch.Size([120, 4, 64, 64])\n",
      "loss forward inputs torch.Size([8, 4, 15, 64, 64]) recon torch.Size([8, 4, 15, 64, 64])\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/eric/Documents/Diffusion/intuitive_physics_pvdm/main.py\", line 96, in <module>\n",
      "    main()\n",
      "  File \"/home/eric/Documents/Diffusion/intuitive_physics_pvdm/main.py\", line 88, in main\n",
      "    first_stage(rank=int(args.devicenum), args=args)\n",
      "  File \"/home/eric/Documents/Diffusion/intuitive_physics_pvdm/exps/first_stage.py\", line 141, in first_stage\n",
      "    first_stage_train(rank, model, opt, d_opt, criterion, train_loader, test_loader, args.first_model, fp, logger)\n",
      "  File \"/home/eric/Documents/Diffusion/intuitive_physics_pvdm/tools/trainer.py\", line 339, in first_stage_train\n",
      "    ae_loss = criterion(vq_loss, x, \n",
      "  File \"/home/eric/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/eric/Documents/Diffusion/intuitive_physics_pvdm/losses/perceptual.py\", line 114, in forward\n",
      "    p_loss = self.perceptual_weight * self.perceptual_loss(inputs_2d.contiguous(), reconstructions_2d.contiguous()).mean()\n",
      "  File \"/home/eric/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/eric/Documents/Diffusion/intuitive_physics_pvdm/losses/lpips.py\", line 86, in forward\n",
      "    in0_input, in1_input = (self.scaling_layer(input), self.scaling_layer(target))\n",
      "  File \"/home/eric/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/eric/Documents/Diffusion/intuitive_physics_pvdm/losses/lpips.py\", line 108, in forward\n",
      "    return (inp - self.shift) / self.scale\n",
      "RuntimeError: The size of tensor a (4) must match the size of tensor b (3) at non-singleton dimension 1\n"
     ]
    }
   ],
   "source": [
    "! python main.py \\\n",
    " --exp first_stage \\\n",
    " --id main \\\n",
    " --pretrain_config configs/autoencoder/base.yaml \\\n",
    " --data UCF101 \\\n",
    " --batch_size 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d541b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# due to use of vgg in lpips.py, lets switch to 3 channels for now\n",
    "# and once that works add in other data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
